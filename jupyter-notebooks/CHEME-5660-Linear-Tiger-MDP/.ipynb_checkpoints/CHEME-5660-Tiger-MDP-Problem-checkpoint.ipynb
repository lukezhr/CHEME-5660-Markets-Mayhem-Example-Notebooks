{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cde366-e417-4e53-bfc8-20a18fcf23ad",
   "metadata": {},
   "source": [
    "## CHEME 5660 The Tiger Problem as a Markov Decision Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1051985-7e86-4c66-bb83-994e1c0ad0d6",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dbaee-739d-4e02-a3e2-8721fb8c636f",
   "metadata": {},
   "source": [
    "### Example setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6aa8155-d399-4482-904f-c3edaa65244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-5660-Markets-Mayhem-Example-Notebooks/jupyter-notebooks/CHEME-5660-Linear-Tiger-MDP`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5660-Markets-Mayhem-Example-Notebooks/jupyter-notebooks/CHEME-5660-Linear-Tiger-MDP/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5660-Markets-Mayhem-Example-Notebooks/jupyter-notebooks/CHEME-5660-Linear-Tiger-MDP/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\".\"); Pkg.resolve(); Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e5ee87-0372-43b4-97a2-02225ae37f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚îå Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "‚îî @ Base loading.jl:1664\n"
     ]
    }
   ],
   "source": [
    "using Distributions\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4362776a-ce7d-40c8-ac18-2f5ef8ca3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"CHEME-5660-Tiger-MDP-CodeLib.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074882e6-d1d5-461b-81ac-2de90d471721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup some global constants -\n",
    "Œ± = 0.75; # probability of moving the direction we are expect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b31d94-e11c-4fd9-9871-d22104f22a88",
   "metadata": {},
   "source": [
    "#### States and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a687bf-4977-4346-8665-8de40248baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the states and actions -\n",
    "safety = 1;\n",
    "tiger = 50;\n",
    "\n",
    "states = range(safety,stop=tiger, step=1) |> collect;\n",
    "actions = [1,2,3]; # a‚ÇÅ = move left, a‚ÇÇ = move right\n",
    "Œ≥ = 0.95;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e118e9ab-4dd3-4f17-8421-ac56a4cdc710",
   "metadata": {},
   "source": [
    "#### Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988a7ae7-5352-480b-aa9a-4286a9b279df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the rewards -\n",
    "R = Array{Float64,2}(undef,length(states), length(actions));\n",
    "fill!(R,0.0) # fill R w/zeros\n",
    "\n",
    "# set the rewards for the ends -\n",
    "R[safety + 1,1] = 10;\n",
    "R[tiger-1, 2] = -100;\n",
    "R[1:length(states), 3] .= -1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d0171-216f-4a53-a2ac-e11f30605ce8",
   "metadata": {},
   "source": [
    "#### Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35205b5f-517c-4bd4-be65-7fe9daad3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the transitions\n",
    "T = Array{Float64,3}(undef, length(states), length(states), length(actions));\n",
    "fill!(T,0.0);\n",
    "\n",
    "# We need to put values into the transition array (these are probabilities, so eah row much sum to 1)\n",
    "T[safety, 1, 1:length(actions)] .= 1.0; # if we are in state 1, we stay in state 1 ‚àÄa ‚àà ùíú\n",
    "T[tiger, tiger, 1:length(actions)] .= 1.0; # if we are in state 5, we stay in state 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bf93f-8f45-4657-84f4-efd81e0a7a7b",
   "metadata": {},
   "source": [
    "##### Left and Right Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ab3482-3840-4156-b51f-8d32ca7b9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left actions -\n",
    "for s ‚àà 2:(tiger - 1)\n",
    "    T[s,s-1,1] = Œ±;\n",
    "    T[s,s+1,1] = (1-Œ±);\n",
    "end\n",
    "\n",
    "# right actions -\n",
    "for s ‚àà 2:(tiger - 1)\n",
    "    T[s,s-1,2] = (1-Œ±);\n",
    "    T[s,s+1,2] = Œ±; \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcdcbe8-b927-42b4-bd40-479af9528119",
   "metadata": {},
   "source": [
    "##### Right action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8753b-1554-4505-9851-d245a2d65d2b",
   "metadata": {},
   "source": [
    "##### Listen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6669ec67-552b-4c20-a082-eb7a1ba0d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen action (we don't move to a new state)\n",
    "for s ‚àà 2:(tiger-1)\n",
    "    T[s,s,3] = 1.0;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7cfca-fe0e-4d4c-aefc-d53a4f4fd745",
   "metadata": {},
   "source": [
    "#### Build the MDP problem object and estimate the utility $U^{\\pi}(s)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfa4d95-a158-41c7-b178-a71b7cc54c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = build(MDP; ùíÆ = states, ùíú = [1,2,3], T = T, R = R, Œ≥ = Œ≥);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4376ec9-db21-4b15-ac68-14c00662707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a always right policy -\n",
    "always_move_right(s) = 2;\n",
    "always_move_left(s) = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0c66f86-93e4-4a70-9e04-dfde6e449383",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = iterative_policy_evaluation(m, always_move_left, 20*length(states));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8d10252-ecb6-4083-975e-95b31543c5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.751516896174223, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a,b) = findmax(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14f0cae7-9272-49c4-88c1-8da62824b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize the policy values -\n",
    "# width = 1.0;\n",
    "# height = 1.0;\n",
    "# y = 0.0;\n",
    "# x = 0.0;\n",
    "\n",
    "# for (i,s) ‚àà enumerate(states)\n",
    "        \n",
    "#     x = x + (width + 0.5)\n",
    "#     if (i == 1)\n",
    "#         plot(rectangle(width, height, x, y), label=\"\")\n",
    "#     else\n",
    "#         plot!(rectangle(width, height, x, y), label=\"\")\n",
    "#     end\n",
    "    \n",
    "# end\n",
    "\n",
    "# current()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca09a4-642f-4b37-939d-91aa26c1b630",
   "metadata": {},
   "source": [
    "#### Q-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "499f1032-207a-4a4e-8578-e21e0e11fa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50√ó3 Matrix{Float64}:\n",
       "  0.0         0.0       -1.0\n",
       " 12.7515      8.25455   11.1139\n",
       " 11.5853     10.5281    10.0061\n",
       " 10.5258      9.56528    8.99951\n",
       "  9.56317     8.69049    8.08501\n",
       "  8.68858     7.89571    7.25415\n",
       "  7.89397     7.17361    6.49927\n",
       "  7.17203     6.51755    5.81343\n",
       "  6.51612     5.92149    5.19031\n",
       "  5.92019     5.37995    4.62418\n",
       "  5.37876     4.88793    4.10982\n",
       "  4.88685     4.4409     3.64251\n",
       "  4.43993     4.03476    3.21793\n",
       "  ‚ãÆ                     \n",
       "  0.366767    0.333297  -0.651571\n",
       "  0.333224    0.302814  -0.683437\n",
       "  0.302747    0.275116  -0.71239\n",
       "  0.275053    0.249939  -0.7387\n",
       "  0.249877    0.227029  -0.762617\n",
       "  0.226953    0.206093  -0.784395\n",
       "  0.205961    0.186673  -0.804337\n",
       "  0.186346    0.167713  -0.822971\n",
       "  0.166733    0.146141  -0.841604\n",
       "  0.142995    0.112191  -0.864155\n",
       "  0.101884  -99.966     -0.90321\n",
       "  0.0         0.0       -1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_array = Q(m, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ae6c8-f546-4e7c-ba97-97030588d022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
