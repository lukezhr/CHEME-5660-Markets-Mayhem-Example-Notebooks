{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8312727f-470f-46ba-bddf-630822894f16",
   "metadata": {},
   "source": [
    "## CHEME 5660 Lab 8: Markov Decision Process (MDP) solution of the Branched Tiger Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715d45e-ffbe-4d02-bee0-450fb91cb00f",
   "metadata": {},
   "source": [
    "<img src=\"./figs/Fig-Branched-MDP-Schematic-no-a-labels.png\" style=\"margin:auto; width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8870c99-4aae-494f-87a7-e1ce3bd0838c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a28aa5b-3634-44a7-a5f9-af0b7a7b9f96",
   "metadata": {},
   "source": [
    "## Lab 8 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368267bf-19ad-4b4f-a86e-bdecbf93f9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-5660-Markets-Mayhem-Example-Notebooks/labs/lab-8-MDP-Tiger-Problem`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5660-Markets-Mayhem-Example-Notebooks/labs/lab-8-MDP-Tiger-Problem/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5660-Markets-Mayhem-Example-Notebooks/labs/lab-8-MDP-Tiger-Problem/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\".\"); Pkg.resolve(); Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98508d0f-d5b9-4494-b283-4b2965e38ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load req packages -\n",
    "using PrettyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b140713-5c3b-4a9a-8bd7-5b142655d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"CHEME-5660-Lab-8-CodeLib.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1146fa85-7837-4d82-a871-36fd01da26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup some global constants -\n",
    "α = 0.95; # probability of moving the direction we are expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21bfa98-1884-4068-99cd-bf0615dc5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the states and actions -\n",
    "safety = 1;\n",
    "tiger = 15;\n",
    "left_reward = -100.0;\n",
    "right_reward = 1000.0;\n",
    "\n",
    "# by pass costs -\n",
    "top_hallway_cost = -20.0;\n",
    "bottom_hallway_cost = -1.0;\n",
    "blocked = -10000.0;\n",
    "\n",
    "states = range(safety,stop=tiger, step=1) |> collect;\n",
    "actions = [1,2,3,4]; # a₁ = move left, a₂ = move right, a₃ = move up, a₄ = move down\n",
    "γ = 0.95;\n",
    "\n",
    "# scenario flag -\n",
    "bottom_hallway_cave_in_flag = false;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95590ae-79d2-49a4-ad96-cd8d866ab3a5",
   "metadata": {},
   "source": [
    "#### Configure the rewards array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8934d3-ec5d-4264-91c1-e01a7a8e4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the rewards -\n",
    "R = Array{Float64,2}(undef,length(states), length(actions));\n",
    "\n",
    "# most of the rewards are zero -\n",
    "fill!(R,0.0) # fill R w/zeros\n",
    "\n",
    "# set the rewards for the ends -\n",
    "R[safety + 1, 1] = left_reward; # if in state 2, and we take action 1 = we live, get married, our kids are all doctors, and we are generally content\n",
    "R[tiger - 1, 2] = right_reward; # if in state N - 1, and we take action 2 = we get eaten. Bad.\n",
    "\n",
    "# linear nodes are blocked -\n",
    "list_linear_nodes = range(10,stop=(tiger-1),step = 1) |> collect\n",
    "for i ∈ list_linear_nodes\n",
    "    R[i,3] = blocked;\n",
    "    R[i,4] = blocked;\n",
    "end\n",
    "\n",
    "# actions:\n",
    "# a₁ = left\n",
    "# a₂ = right\n",
    "# a₃ = up\n",
    "# a₄ = down\n",
    "\n",
    "# rewards for the by-passes. \n",
    "R[2,3] = top_hallway_cost;\n",
    "R[2,4] = bottom_hallway_cost;\n",
    "R[2,2] = blocked;\n",
    "R[9,1] = blocked;\n",
    "R[9,3] = top_hallway_cost;\n",
    "R[9,4] = bottom_hallway_cost;\n",
    "\n",
    "# top -\n",
    "R[3,1] = blocked;\n",
    "R[3,2] = top_hallway_cost\n",
    "R[3,3] = blocked;\n",
    "R[4,1] = top_hallway_cost\n",
    "R[4,2] = top_hallway_cost\n",
    "R[4,3] = blocked;\n",
    "R[4,4] = blocked;\n",
    "R[5,1] = top_hallway_cost\n",
    "R[5,2] = blocked;\n",
    "R[5,3] = blocked;\n",
    "\n",
    "# bottom -\n",
    "R[6,1] = blocked;\n",
    "R[6,2] = bottom_hallway_cost;\n",
    "R[6,4] = blocked;\n",
    "R[7,1] = bottom_hallway_cost;\n",
    "R[7,2] = bottom_hallway_cost;\n",
    "R[7,3] = blocked;\n",
    "R[7,4] = blocked;\n",
    "R[8,1] = bottom_hallway_cost;\n",
    "R[8,2] = blocked;\n",
    "R[8,4] = blocked;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c110013-4c5d-4759-8646-05ae9ce940b1",
   "metadata": {},
   "source": [
    "#### Configure the transition array $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b160d5-3a73-4e29-8b43-a67beba9b798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the transitions\n",
    "T = Array{Float64,3}(undef, length(states), length(states), length(actions));\n",
    "fill!(T,0.0);\n",
    "\n",
    "# We need to put values into the transition array (these are probabilities, so eah row much sum to 1)\n",
    "T[safety, 1, 1:length(actions)] .= 1.0; # if we are in state 1, we stay in state 1 ∀a ∈ 𝒜\n",
    "T[tiger, tiger, 1:length(actions)] .= 1.0; # if we are in state 5, we stay in state 5 \n",
    "\n",
    "# left actions -\n",
    "for s ∈ 2:(tiger - 1)\n",
    "    T[s,s-1,1] = α;\n",
    "    T[s,s+1,1] = (1-α);\n",
    "end\n",
    "\n",
    "# right actions -\n",
    "for s ∈ 2:(tiger - 1)\n",
    "    T[s,s-1,2] = (1-α);\n",
    "    T[s,s+1,2] = α; \n",
    "end\n",
    "\n",
    "# Node 2 -\n",
    "T[2,:,2] .= 0.0\n",
    "T[2,3,3] = α;\n",
    "T[2,6,3] = (1-α);\n",
    "T[2,6,4] = α;\n",
    "T[2,3,4] = (1-α);\n",
    "T[2,2,2] = 1.0; # node 2 can't go right\n",
    "\n",
    "# Node 3 -\n",
    "T[3,:,:] .= 0.0\n",
    "T[3,3,1] = 1.0;\n",
    "T[3,4,2] = α;\n",
    "T[3,3,2] = (1-α);\n",
    "T[3,3,3] = 1.0;\n",
    "T[3,2,4] = α;\n",
    "T[3,3,4] = (1-α);\n",
    "\n",
    "# Node 4 -\n",
    "T[4,4,3] = 1.0;\n",
    "T[4,4,4] = 1.0;\n",
    "\n",
    "# Node 5 -\n",
    "T[5,:,:] .= 0.0;\n",
    "T[5,4,1] = α;\n",
    "T[5,5,1] = (1-α);\n",
    "T[5,5,2] = 1.0;\n",
    "T[5,5,3] = 1.0;\n",
    "T[5,9,4] = α;\n",
    "T[5,5,4] = (1-α);\n",
    "\n",
    "# Node 6 -\n",
    "T[6,:,:] .= 0.0;\n",
    "T[6,6,1] = 1.0;\n",
    "T[6,7,2] = α;\n",
    "T[6,6,2] = (1-α);\n",
    "T[6,2,3] = α;\n",
    "T[6,6,3] = (1-α);\n",
    "T[6,6,4] = 1.0;\n",
    "\n",
    "# Node 7 -\n",
    "T[7,7,3] = 1.0;\n",
    "T[7,7,4] = 1.0;\n",
    "\n",
    "# Node 8 -\n",
    "T[8,:,:] .= 0.0\n",
    "T[8,7,1] = α;\n",
    "T[8,8,1] = (1-α);\n",
    "T[8,8,2] = 1.0;\n",
    "T[8,9,3] = α;\n",
    "T[8,8,3] = (1-α);\n",
    "T[8,8,4] = 1.0;\n",
    "\n",
    "# Node 9 -\n",
    "T[9,:,:] .= 0.0;\n",
    "T[9,9,1] = 1.0;\n",
    "T[9,10,2] = α;\n",
    "T[9,9,2] = (1-α);\n",
    "T[9,5,3] = α;\n",
    "T[9,9,3] = (1-α);\n",
    "T[9,8,4] = α;\n",
    "T[9,9,4] = (1-α);\n",
    "\n",
    "# Nodes 10 -> end\n",
    "for s = 10:(tiger-1)\n",
    "    T[s,s,3] = 1.0\n",
    "    T[s,s,4] = 1.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7092317c-adb8-49ff-9724-77f991c406b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-configure setup to include bttom hallway cave in\n",
    "if (bottom_hallway_cave_in_flag == true)\n",
    "    \n",
    "    # configure rewards -\n",
    "    R[6,2] = blocked;\n",
    "    R[8,1] = blocked;\n",
    "\n",
    "    # configure T array -\n",
    "    # node 6 -\n",
    "    T[6,:,:] .= 0.0;\n",
    "    T[6,6,1] = 1.0; # we stay in 6 if we go left\n",
    "    T[6,6,2] = 1.0; # we stay in 6 if we go right\n",
    "    T[6,2,3] = α; \n",
    "    T[6,6,3] = (1-α);\n",
    "    T[6,6,4] = 1.0; # we stay in 6 if we go down\n",
    "    \n",
    "    # node 8 -\n",
    "    T[8,:,:] .= 0.0;\n",
    "    T[8,9,3] = α; \n",
    "    T[8,8,3] = (1 - α); \n",
    "    T[8,8,1] = 1.0; # we stay in 8 if we go left\n",
    "    T[8,8,2] = 1.0; # we stay in 8 if we go right\n",
    "    T[8,8,4] = 1.0; # we stay in 8 if we go down\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1781bae-e6d9-4278-a565-46614de13252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬───────────┬────────────┬─────────┬───────────┐\n",
      "│\u001b[1m State s \u001b[0m│\u001b[1m a₁ (left) \u001b[0m│\u001b[1m a₂ (right) \u001b[0m│\u001b[1m a₃ (up) \u001b[0m│\u001b[1m a₄ (down) \u001b[0m│\n",
      "├─────────┼───────────┼────────────┼─────────┼───────────┤\n",
      "│       1 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       2 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       3 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       4 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       5 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       6 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       7 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       8 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│       9 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│      10 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│      11 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│      12 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│      13 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│      14 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "│      15 │       1.0 │        1.0 │     1.0 │       1.0 │\n",
      "└─────────┴───────────┴────────────┴─────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# row summation check -\n",
    "T_array_check_table = Array{Any,2}(undef, length(states), length(actions)+1)\n",
    "\n",
    "for s ∈ 1:length(states)\n",
    "    T_array_check_table[s,1] = s;\n",
    "end\n",
    "\n",
    "for a ∈ 1:length(actions)\n",
    "    \n",
    "    # sum the action table -\n",
    "    Z = sum(T[:,:,a], dims=2)\n",
    "    \n",
    "    for s ∈ 1:length(states)\n",
    "        T_array_check_table[s,a+1] = Z[s]\n",
    "    end\n",
    "end\n",
    "\n",
    "# header -\n",
    "T_check_header = ([\"State s\", \"a₁ (left)\", \"a₂ (right)\", \"a₃ (up)\", \"a₄ (down)\"]);\n",
    "\n",
    "# display -\n",
    "pretty_table(T_array_check_table; header=T_check_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25960165-2f78-4737-8184-d48d0d9fab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp_problem = build(MDPProblem; 𝒮 = states, 𝒜 = actions, T = T, R = R, γ = γ);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "951c15bb-bc1c-4827-b00e-3aa3a0305e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = solve(mdp_problem,1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09169577-9d50-4ee6-a355-2e015900bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Q array -\n",
    "Q_array = Q(mdp_problem, U)\n",
    "\n",
    "# compute the policy -\n",
    "policy = π(Q_array);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d546b2f-4973-4841-97ca-b8a7e019c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬───────────┬──────┬──────────┬──────────┬──────────┬──────────┐\n",
      "│\u001b[1m State \u001b[0m│\u001b[1m Direction \u001b[0m│\u001b[1m π(s) \u001b[0m│\u001b[1m  U(a₁) l \u001b[0m│\u001b[1m  U(a₂) r \u001b[0m│\u001b[1m  U(a₃) u \u001b[0m│\u001b[1m  U(a₄) d \u001b[0m│\n",
      "├───────┼───────────┼──────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│     1 │      stop │    0 │      0.0 │      0.0 │      0.0 │      0.0 │\n",
      "│     2 │      down │    4 │ -47.5291 │ -8950.58 │  1029.47 │  1049.42 │\n",
      "│     3 │      down │    4 │ -8950.58 │  1013.32 │ -8950.58 │  1049.42 │\n",
      "│     4 │     right │    2 │  1029.58 │  1032.47 │ -8967.53 │ -8967.53 │\n",
      "│     5 │      down │    4 │  1013.48 │ -8947.37 │ -8947.37 │  1052.63 │\n",
      "│     6 │     right │    2 │ -8949.53 │  1050.47 │  1049.47 │ -8949.53 │\n",
      "│     7 │     right │    2 │  1049.58 │  1051.52 │ -8948.48 │ -8948.48 │\n",
      "│     8 │        up │    3 │  1050.58 │ -8947.37 │  1052.63 │ -8947.37 │\n",
      "│     9 │     right │    2 │ -8947.37 │  1052.63 │  1032.63 │  1051.63 │\n",
      "│    10 │      left │    1 │  1052.63 │  1052.63 │ -8947.37 │ -8947.37 │\n",
      "│    11 │      left │    1 │  1052.63 │  1052.63 │ -8947.37 │ -8947.37 │\n",
      "│    12 │      left │    1 │  1052.63 │  1052.63 │ -8947.37 │ -8947.37 │\n",
      "│    13 │      left │    1 │  1052.63 │  1052.63 │ -8947.37 │ -8947.37 │\n",
      "│    14 │     right │    2 │   1000.0 │  1052.63 │ -8947.37 │ -8947.37 │\n",
      "│    15 │      stop │    0 │      0.0 │      0.0 │      0.0 │      0.0 │\n",
      "└───────┴───────────┴──────┴──────────┴──────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# make a Q-table -\n",
    "Q_table_data_array = Array{Any,2}(undef, length(states), length(actions)+3)\n",
    "\n",
    "for s ∈ 1:length(states)\n",
    "    \n",
    "    Q_table_data_array[s,1] = s;\n",
    "    \n",
    "    direction = \"left\"\n",
    "    policy_index = policy[s];\n",
    "    if policy_index == 2\n",
    "        direction = \"right\" \n",
    "    elseif policy_index == 3\n",
    "         direction = \"up\" \n",
    "    elseif policy_index == 4\n",
    "         direction = \"down\" \n",
    "    elseif policy_index == 0\n",
    "        direction = \"stop\"\n",
    "    end\n",
    "    \n",
    "    Q_table_data_array[s,2] = direction;\n",
    "    Q_table_data_array[s,3] = policy_index;\n",
    "    \n",
    "    \n",
    "    for a ∈ 1:length(actions)\n",
    "        Q_table_data_array[s,a+3] = Q_array[s,a];\n",
    "    end\n",
    "end\n",
    "\n",
    "# header -\n",
    "Q_table_header = ([\"State\", \"Direction\", \"π(s)\", \"U(a₁) l\", \"U(a₂) r\", \"U(a₃) u\", \"U(a₄) d\"])\n",
    "\n",
    "# show -\n",
    "pretty_table(Q_table_data_array; header = Q_table_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d1522c-e450-4540-9721-78f6a5e0fdbc",
   "metadata": {},
   "source": [
    "<img src=\"./figs/Fig-Branched-MDP-Schematic-no-a-labels.png\" style=\"width:50%; align:left\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
